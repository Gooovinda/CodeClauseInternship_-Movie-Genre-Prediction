{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab1b0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drama              1206\n",
      "Comedy             1042\n",
      "Action              754\n",
      "Adventure           339\n",
      "Horror              300\n",
      "Crime               195\n",
      "Thriller            194\n",
      "Animation           123\n",
      "Fantasy             117\n",
      "Romance             106\n",
      "Science Fiction      96\n",
      "Documentary          87\n",
      "Family               56\n",
      "Mystery              41\n",
      "Music                34\n",
      "Western              27\n",
      "History              25\n",
      "War                  24\n",
      "TV Movie              4\n",
      "Foreign               2\n",
      "Name: main_genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "movies_df = pd.read_csv('tmdb_5000_movies.csv')\n",
    "\n",
    "# Drop rows with missing overviews or genres\n",
    "movies_df = movies_df.dropna(subset=['overview', 'genres'])\n",
    "\n",
    "# Extract the first genre name from the genres column\n",
    "def extract_main_genre(genre_str):\n",
    "    try:\n",
    "        genres = json.loads(genre_str.replace(\"'\", '\"'))\n",
    "        if genres:\n",
    "            return genres[0]['name']  # Use only the first genre as label\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "movies_df['main_genre'] = movies_df['genres'].apply(extract_main_genre)\n",
    "movies_df = movies_df.dropna(subset=['main_genre'])\n",
    "\n",
    "# Check class distribution\n",
    "print(movies_df['main_genre'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8451b792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4153, 21)\n",
      "Drama        1206\n",
      "Comedy       1042\n",
      "Action        754\n",
      "Adventure     339\n",
      "Horror        300\n",
      "Crime         195\n",
      "Thriller      194\n",
      "Animation     123\n",
      "Name: main_genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# I want to focus on the most common genres, so I'm keeping only the top 8\n",
    "top_genres = movies_df['main_genre'].value_counts().nlargest(8).index.tolist()\n",
    "\n",
    "# Now I’ll filter the dataset to include only those top genres\n",
    "filtered_df = movies_df[movies_df['main_genre'].isin(top_genres)].copy()\n",
    "\n",
    "# Just checking how many rows are left and which genres are included\n",
    "print(filtered_df.shape)\n",
    "print(filtered_df['main_genre'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd12b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\govin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\govin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>clean_overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>nd century paraplegic marine dispatched moon p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>captain barbossa long believed dead come back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>cryptic message bonds past sends trail uncover...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...   \n",
       "1  Captain Barbossa, long believed to be dead, ha...   \n",
       "2  A cryptic message from Bond’s past sends him o...   \n",
       "\n",
       "                                      clean_overview  \n",
       "0  nd century paraplegic marine dispatched moon p...  \n",
       "1  captain barbossa long believed dead come back ...  \n",
       "2  cryptic message bonds past sends trail uncover...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download only what's needed\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# I’m keeping this simple — just cleaning and removing stopwords, no lemmatization\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # lowercase the text\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # remove punctuation and numbers\n",
    "    words = nltk.word_tokenize(text)  # tokenize words\n",
    "    words = [word for word in words if word not in stop_words]  # remove stopwords\n",
    "    return ' '.join(words)  # join back to a cleaned string\n",
    "\n",
    "# Applying this to all overviews\n",
    "filtered_df['clean_overview'] = filtered_df['overview'].apply(preprocess_text)\n",
    "\n",
    "# Let me check a few cleaned samples\n",
    "filtered_df[['overview', 'clean_overview']].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5491070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (4153, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# I'm limiting the max features to 5000 for performance (you can tune this)\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Applying TF-IDF on the cleaned overview column\n",
    "X = tfidf.fit_transform(filtered_df['clean_overview']).toarray()\n",
    "\n",
    "# These are our input features now\n",
    "print(\"TF-IDF shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e24558b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Classes: ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Drama', 'Horror', 'Thriller']\n",
      "Target shape: (4153,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# I'm creating the label encoder instance\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fitting it on the main_genre column and transforming it\n",
    "y = le.fit_transform(filtered_df['main_genre'])\n",
    "\n",
    "# Let’s check how classes were encoded\n",
    "print(\"Encoded Classes:\", list(le.classes_))\n",
    "print(\"Target shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0af9ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4452466907340554\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.50      0.48       151\n",
      "           1       0.40      0.03      0.05        68\n",
      "           2       0.00      0.00      0.00        25\n",
      "           3       0.46      0.57      0.51       208\n",
      "           4       0.00      0.00      0.00        39\n",
      "           5       0.43      0.68      0.53       241\n",
      "           6       0.62      0.13      0.22        60\n",
      "           7       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.45       831\n",
      "   macro avg       0.29      0.24      0.22       831\n",
      "weighted avg       0.40      0.45      0.39       831\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\govin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\govin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Use X instead of X_tfidf\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35419d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4153, 5000)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "614b1598",
   "metadata": {},
   "source": [
    "* Insights\n",
    "The model achieved ~44% accuracy using only plot summaries, showing that genre prediction from text is possible.\n",
    "Genres like Drama and Comedy performed better due to more data.\n",
    "Less frequent genres like Horror and Animation had low performance.\n",
    "TF-IDF gave a decent start, but more advanced techniques like BERT could improve results.\n",
    "The model is biased toward dominant genres, and multilabel classification could better reflect real-world movie genres."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
